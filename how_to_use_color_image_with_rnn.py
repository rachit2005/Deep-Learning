# -*- coding: utf-8 -*-
"""how to use color image with rnn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1elfn7pZGmdO641V-SVznYbj4HAw6YlWg

# How to reshape an colored image for rnn/lstm/gru nn used models
"""

import torch
import torchvision
from torch import nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

INPUT_SIZE = 32
sequnece_length = 32
NUM_CLASSES = 10
LEARNING_RATE = 0.01
BATCH_SIZE = 32
NUM_EPOCHS = 1
num_layer = 2
hidden_size = 256


# downloading a colored image dataset for demonstration
train_dataset_fashion = datasets.CIFAR10(root="root" , train=False , transform=transforms.ToTensor() , download=True)
train_loader_fashion = DataLoader(train_dataset_fashion , BATCH_SIZE , shuffle=True)

image , label = train_dataset_fashion[0]

for batch in train_loader_fashion:
    img , lab = batch
    # image shape --> [32 , 1, 32 , 32] and its index is [0,1,2,3]
    out = img.view(image.size(0) , image.size(2) , -1) # --> shape [32 , 32 , 32*3]
    # print(f"imag shape for rnn is [batch , seq , feq] --> {img.reshape(-1 , 28,28).shape} || og shape {img.shape}")
    print(f"image shape {img.shape}")
    print(out.shape)
    break


class RNN(nn.Module):
    def __init__(self, input_size , hidden_size , num_layer , output_size):
        # input --> [1,28,28]
        super(RNN , self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layer
        # for batch first --> (batch_size x no_of_seq x no_of_features)
        # self.rnn = nn.RNN(input_size=input_size , hidden_size=hidden_size , num_layers=num_layer, batch_first=True)
        # self.gru = nn.GRU(input_size=input_size , hidden_size=hidden_size , num_layers=num_layer, batch_first=True)

        self.lstm = nn.LSTM(input_size , hidden_size , num_layer , batch_first=True)

        # after rnn , output --> [1,28,256] , hidden state output --> [2,1,256] as we have passed it in forward function
        self.fc = nn.Linear(hidden_size , output_size)
        # output --> [1 , 10]

    def forward(self , x):
        # print(x.shape) --> [1,28,28]
        h0 = torch.zeros(self.num_layers, x.size(0) , self.hidden_size)
        # since the lstm has cell state which is not in the case of rnn and gru
        c0 = torch.zeros(self.num_layers , x.size(0) , self.hidden_size)

        # print(h0.shape) --> [2,1,256]
        # out , h1 = self.rnn(x , h0)
        # out , h1 = self.gru(x , h0)

        out , h1 = self.lstm(x , (h0 , c0))
        # out = out.reshape(out.shape[0] , -1) # --> [batch_size , 28*28]
        out = self.fc(out[:,-1, :])
        return out


model = RNN(INPUT_SIZE , hidden_size , num_layer , NUM_CLASSES)
y = model(image)
print(y.shape)
print(image.shape)

loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(params=model.parameters() , lr= LEARNING_RATE)

for epoch in range(NUM_EPOCHS):
    model.train()
    for batch , (image1 , label) in enumerate(train_loader_fashion):
        # print(image.shape)
        # image = image.squeeze(1)

        # print(f"after reshaping {image.shape}")
        print(image1.shape)
        print(image1.size(0))
        print(image1.size(1))
        print(image1.size(2))
        print(image1.size(3))
        image1 = image1.view(image1.size(0) , image1.size(2) , -1)
        print("after reshaping")
        # (batch_size, seq_length, input_size) so now the input size is 32*3
        print(image1.shape)
        print(image1.size(0))
        print(image1.size(1))
        print(image1.size(2))


        break

