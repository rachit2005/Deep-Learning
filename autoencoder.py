# -*- coding: utf-8 -*-
"""autoencoder.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18BabQUmF7RztyW8fAm6Tgoj0Nl_yBvG5
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.datasets as Datasets
import torchvision.transforms as transforms
import torch.nn.functional as F
import torchvision.models as models
import torchvision.utils as vutils

import os
import random
import numpy as np
import math
from IPython.display import clear_output
import matplotlib.pyplot as plt
from PIL import Image
from tqdm.notebook import trange, tqdm

BATCH_SIZE = 32
# Define learning rate
lr = 1e-4
# Number of Training epochs
epochs = 110
# Scale for the added image noise
noise_scale = 0.3

"""Create an MNIST dataset and dataloader"""
transform = transforms.Compose([
                # transforms.Resize(32),
                transforms.ToTensor(),
                transforms.Normalize([0.5], [0.5])])

train_set = Datasets.MNIST(root='root', train=True, transform=transform, download=True)
train_dataloader = DataLoader(train_set, batch_size=BATCH_SIZE,shuffle=True, num_workers=4)

test_set = Datasets.MNIST(root='root', train=False, transform=transform, download=True)
test_dataloader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

class AutoEncoder(nn.Module):
        def __init__(self):
            super().__init__()
            # (batch_size , 784)
            self.encoder = nn.Sequential(
                nn.Linear(784 , 512),
                nn.ReLU(),
                nn.Linear(512 , 128),
                nn.ReLU(),
                nn.Linear(128 , 64),
                nn.ReLU(),
                nn.Linear(64 , 3) # out --> batch_size , 3
            )

            self.deccoder = nn.Sequential(
                nn.Linear(3,64),
                nn.ReLU(),
                nn.Linear(64,128),
                nn.ReLU(),
                nn.Linear(128,512),
                nn.ReLU(),
                nn.Linear(512 , 784),
                nn.Sigmoid()
            )
        def forward(self , x):
          return self.deccoder(self.encoder(x))

model = AutoEncoder()
loss_function = nn.MSELoss()
optimi = torch.optim.SGD(params=model.parameters() , lr=0.01)

for epoch in range(epochs):
  output = []
  model.train()
  for batch , (img , label) in enumerate(train_dataloader):
    img = img.reshape(-1 , 784)
    out = model(img)
    loss = loss_function(out , img)

    optimi.zero_grad()
    loss.backward()
    optimi.step()

  print(f"epoch { epoch+1} | loss {loss.item()}")
  output.append((epoch , img , out))

for k in range(len(output)):
  plt.figure(figsize=(9,2))
  imgs = output[k][1].detach().numpy()
  out = output[k][2].detach().numpy()

  for i , item in enumerate(imgs):
    if i>=9:break
    plt.subplot(2,9,i+1)
    item = item.reshape(-1 , 28,28)
    plt.imshow(item[0])

  for i , item in enumerate(out):
    if i>=9:break
    plt.subplot(2,9,9+i+1)
    item = item.reshape(-1 , 28,28)
    plt.imshow(item[0])

class AutoEncoder_CNN(nn.Module):
  def __init__(self):
    super().__init__()
    # n , 1,28,28
    self.encoder = nn.Sequential(
        nn.Conv2d(in_channels = 1 , out_channels = 16 , kernel_size = 3 , stride = 2 , padding = 1), # n,16,14,14
        nn.ReLU(),
        nn.Conv2d(16,32,3,stride=2,padding=1), #n,32 , 7,7
        nn.ReLU(),
        nn.Conv2d(32,64,3,stride=1,padding=1), # n,64 , 7,7
    )

    self.decoder = nn.Sequential(
        nn.ConvTranspose2d(64,32,3,stride=1,padding=1), # n,32,7,7
        nn.ReLU(),
        nn.ConvTranspose2d(32,16,3,stride=2,padding=1 , output_padding=1), # n,16,14,14
        nn.ReLU(),
        nn.ConvTranspose2d(16,1,3,stride=2 , padding=1,output_padding=1),# n,1,28,28
        nn.Sigmoid()
        )

  def forward(self , x):
    return self.decoder(self.encoder(x))

model_2 = AutoEncoder_CNN()
loss_function = nn.MSELoss()
optimi = torch.optim.SGD(params=model_2.parameters() , lr=0.01)
outputs = []

for epoch in range(epochs):
  model_2.train()
  for img , label in train_dataloader:
    out = model_2(img)
    outputs.append((out , img , epoch))
    loss = loss_function(out , img)

    optimi.zero_grad()
    loss.backward()
    optimi.step()

  print(f"epoch {epoch} || loss {loss}")

for k in range(len(outputs)):
  plt.figure(figsize=(9,2))
  imgs = outputs[k][1].detach().numpy() # Use outputs instead of output
  out = outputs[k][0].detach().numpy() # Use outputs instead of output, and index 0 for the output of the model

  for i , item in enumerate(imgs):
    if i>=9:break
    plt.subplot(2,9,i+1)
    item = item.reshape(-1 , 28,28)
    plt.imshow(item[0])

  for i , item in enumerate(out):
    if i>=9:break
    plt.subplot(2,9,9+i+1)
    item = item.reshape(-1 , 28,28)
    plt.imshow(item[0])

  plt.show()

